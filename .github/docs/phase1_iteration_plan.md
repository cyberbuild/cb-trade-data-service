# Phase 1 Iteration Plan: Dedicated Data Service (cb-trade)

This document provides a step-by-step iteration plan for implementing Phase 1 of your financial model project: the Foundation Setup & Dedicated Data Service. This plan breaks down the development of the Data Service into smaller, actionable steps, building upon the architectural overview defined in the Phase 1 Implementation Plan document.

The project prefix will be cb-trade. Repositories will follow the naming convention cb-trade-[service-name]. The Data Service repository will be initialized under the cyberbuild GitHub organization.

The system will utilize a single Conda environment for the entire system for initial development and deployment. (Note: While convenient for development, a production system might benefit from per-service isolated environments).

Raw data storage will be file-based, organized by coin symbol in a folder structure, abstracting access via interfaces to support different storage backends (Local, Azure Storage). The list of registered coins will be determined by the presence of these coin folders in the storage location. A common utility will be used for constructing storage paths.

Testing Framework: All tests will be implemented using pytest.

## Iteration 1: Basic Environment & File Storage Setup

**Goal**: Set up the core development environment and establish the foundational file-based data storage abstraction.

### 1.1 Dev Environment Setup:
- Create and configure the single Conda environment for the entire cb-trade system. Install core libraries: python, pandas, numpy, pytest.
- Initialize the Git repository for the Data Service: github.com/cyberbuild/cb-trade-data-service.
- Set up basic project structure for the Data Service.

### 1.2 Design Raw Data File Structure & Implement Path Construction Utility:
- Define the standardized file naming convention and folder structure for storing raw 5-minute order book data. The structure is:
  ```
  [storage_root]/raw_data/[exchange_name]/[coin_symbol]/[year]/[month]/[day]/[timestamp].json
  ```
  - [storage_root]: This is the configurable base path for the storage. For LocalFileStorage, it's a local directory path. For AzureBlobStorage, it corresponds to the container name.
  - raw_data/: A static sub-directory.
  - [exchange_name]/: A directory named after the cryptocurrency exchange (e.g., binance/).
  - [coin_symbol]/: A directory named after the coin symbol (e.g., BTC/).
  - [year]/, [month]/, [day]/: Nested directories based on the year, month, and day extracted from the data entry's timestamp.
  - [timestamp].json: The file name, where [timestamp] is the timestamp of the data entry (e.g., Unix timestamp or ISO format).

- Implement a StoragePathUtility class or module with methods to generate these standardized path strings.
  - Step 1: Create a Python file for the utility at the following path: data-service/src/storage/path_utility.py.
  - Step 2: Define a Python class or module named StoragePathUtility within this file.
  - Step 3: Define a method within StoragePathUtility called get_raw_data_path.
  - Step 4: This method should accept parameters: exchange_name (string), coin_symbol (string), and timestamp (a datetime object or a value from which year, month, day, and a file-safe timestamp can be extracted).
  - Step 5: Inside the method, extract the year, month, and day from the timestamp. Format the timestamp into a string suitable for a filename (e.g., Unix timestamp or YYYYMMDDHHMMSS).
  - Step 6: Construct the path string using the defined format: raw_data/{exchange_name}/{coin_symbol}/{year}/{month}/{day}/{timestamp_filename}.json. Note that [storage_root] is not included in the string generated by this utility; it's handled by the storage implementation.
  - Step 7: Return the constructed path string.

**Test Cases**
- Test File Path: data-service/tests/unit/storage/test_path_utility.py
- Test get_raw_data_path with valid inputs (exchange, coin, timestamp) to ensure correct path format.
- Test get_raw_data_path with edge cases (e.g., start/end of year/month).
- Test get_raw_data_path with different data types for inputs (if applicable) to ensure type handling.

### 1.3 Design IRawDataStorage Interface:
- Define the interface IRawDataStorage with methods for:
  - save_entry(exchange_name, coin_symbol, timestamp, data): Saves a single raw data entry.
  - get_range(exchange_name, coin_symbol, start_time, end_time, limit, offset): Retrieves entries within a time range.
  - get_latest_entry(exchange_name, coin_symbol): Retrieves the single latest entry.
  - list_coins(exchange_name): Lists all available coin symbols for a given exchange (based on folder names).
  - check_coin_exists(exchange_name, coin_symbol): Checks if a folder for a coin exists for a given exchange.
- Step 1: Create a Python file for the interface at the following path: data-service/src/storage/interfaces.py.
- Step 2: Define the IRawDataStorage interface (using abc module) within this file.

### 1.4 Implement LocalFileStorage:
- Implement a concrete class LocalFileStorage that implements IRawDataStorage.
- Step 1: Create a Python file for the implementation at the following path: data-service/src/storage/implementations/local_file_storage.py.
- Step 2: Define the LocalFileStorage class within this file, inheriting from IRawDataStorage.
- This class will use the StoragePathUtility to construct local file paths based on the defined structure.
- Implement logic for reading and writing files according to these paths.
- Write unit tests for LocalFileStorage methods (saving, basic retrieval, listing coins).

**Test Cases**
- Test File Path: data-service/tests/unit/storage/implementations/test_local_file_storage.py
- Test save_entry for a new coin/exchange: verify folder and file creation.
- Test save_entry for an existing coin/exchange: verify file creation in the correct folder.
- Test get_range with a valid time range and existing data: verify correct entries are returned.
- Test get_range with an empty time range: verify empty list is returned.
- Test get_range with a time range containing no data: verify empty list is returned.
- Test get_range with limit and offset: verify pagination works correctly.
- Test get_latest_entry for a coin with data: verify the most recent entry is returned.
- Test get_latest_entry for a coin with no data: verify None or appropriate indicator is returned.
- Test list_coins for an exchange with coins: verify correct list of coin symbols is returned.
- Test list_coins for an exchange with no coins: verify empty list is returned.
- Test check_coin_exists for an existing coin/exchange: verify True is returned.
- Test check_coin_exists for a non-existing coin/exchange: verify False is returned.
- Test error handling for file system issues (e.g., permissions, disk full) during save/read operations.

### 1.5 Implement AzureBlobStorage Concrete Class:
- Implement a concrete class AzureBlobStorage that implements IRawDataStorage. This iteration includes the full implementation for interacting with Azure Blob Storage.
- Step 1: Create a Python file for the implementation at the following path: data-service/src/storage/implementations/azure_blob_storage.py.
- Step 2: Define the AzureBlobStorage class within this file, inheriting from IRawDataStorage.
- This class will use the StoragePathUtility to construct blob paths/names.
- Implement logic for connecting to Azure, creating containers/folders, and reading/writing blobs according to the defined file structure, using the Azure Blob Storage SDK.

**Test Cases**
- Test File Path: data-service/tests/unit/storage/implementations/test_azure_blob_storage.py
- Test save_entry to Azure Blob Storage: verify blob is created in the correct container/path.
- Test get_range from Azure Blob Storage: verify correct blobs are retrieved and data is parsed.
- Test get_latest_entry from Azure Blob Storage: verify the most recent blob is retrieved.
- Test list_coins from Azure Blob Storage: verify correct list of coin folders is returned.
- Test check_coin_exists in Azure Blob Storage: verify existence check works correctly.
- Test handling of Azure API errors (e.g., connection issues, authentication failures).

### 1.6 Design and Implement IStorageManager and StorageManagerImpl:
- Define the IStorageManager interface (this might be very similar to IRawDataStorage initially, or add orchestration logic).
- Step 1: Create a Python file for the manager implementation at the following path: data-service/src/storage/manager.py.
- Step 2: Define the StorageManagerImpl class within this file, which will depend on an instance of IRawDataStorage (injected dependency).
- Write unit tests for StorageManagerImpl methods, ensuring they correctly delegate to the injected IRawDataStorage implementation.

**Test Cases**
- Test File Path: data-service/tests/unit/storage/test_manager.py
- Test StorageManagerImpl methods (save, get_range, get_latest, list_coins, check_coin_exists) with an injected LocalFileStorage mock/instance: verify calls are correctly passed to the underlying storage.
- Test StorageManagerImpl methods with an injected AzureBlobStorage mock/instance: verify calls are correctly passed.

### 1.7 Configure Storage Backend:
- Implement a configuration mechanism (e.g., environment variables, config file) to select which IRawDataStorage implementation (LocalFileStorage or AzureBlobStorage) to use at runtime.

## Iteration 2: Data Source Connector (Microkernel Core & Basic Plugin)

**Goal**: Implement the core Microkernel logic and a basic, perhaps mocked, exchange plugin.

### 2.1 Design and Implement IExchangeAPIClient:
- Define the core IExchangeAPIClient interface with methods like get_exchange_name, fetch_historical_data, start_realtime_stream, check_coin_availability.
- Step 1: Create a Python file for the interface at the following path: data-service/src/exchange_source/interfaces.py.
- Step 2: Define the IExchangeAPIClient interface (using abc module) within this file.

### 2.2 Design and Implement PluginRegistry:
- Implement a PluginRegistry class to store IExchangeAPIClient instances, mapping exchange names to clients.
- Step 1: Create a Python file for the registry at the following path: data-service/src/exchange_source/microkernel.py.
- Step 2: Define the PluginRegistry class within this file.

**Test Cases**
- Test File Path: data-service/tests/unit/exchange_source/test_microkernel.py (Tests for PluginRegistry and DataSourceConnectorImpl)
- Test adding a plugin to the registry.
- Test retrieving a plugin by name.
- Test attempting to retrieve a non-existent plugin.
- Test adding multiple plugins with unique names.
- Test attempting to add a plugin with a name that already exists.

### 2.3 Design and Implement IDataSourceConnector and DataSourceConnectorImpl (Microkernel):
- Define the IDataSourceConnector interface.
- Step 1: Add the IDataSourceConnector interface definition to the file created in 2.1: data-service/src/exchange_source/interfaces.py.
- Implement DataSourceConnectorImpl. This class will:
  - Discover and register IExchangeAPIClient plugins (initially, manually register a mock or basic implementation).
  - Provide a method get_client(exchange_name) to retrieve the correct plugin from the PluginRegistry.
  - Delegate calls like check_coin_availability and fetch_historical_data to the retrieved plugin.
- Step 2: Add the DataSourceConnectorImpl class to the file created in 2.2: data-service/src/exchange_source/microkernel.py.
- Write unit tests for DataSourceConnectorImpl, ensuring correct plugin retrieval and delegation.

**Test Cases**
- Test File Path: data-service/tests/unit/exchange_source/test_microkernel.py (Tests for PluginRegistry and DataSourceConnectorImpl)
- Test get_client with a registered exchange name: verify the correct plugin instance is returned.
- Test get_client with a non-registered exchange name: verify appropriate error handling (e.g., raising an exception).
- Test delegation of check_coin_availability to a mock plugin: verify the call is made with correct arguments and the result is returned.
- Test delegation of fetch_historical_data to a mock plugin: verify the call is made with correct arguments and the result is returned.
- Test delegation of start_realtime_stream to a mock plugin: verify the call is made with correct arguments.
- Test plugin discovery mechanism (if implemented): verify correct plugins are loaded and registered on startup.

### 2.4 Implement a Concrete CCXT IExchangeAPIClient Plugin:

Implement a concrete class `CCXTExchangeClient` that implements `IExchangeAPIClient` using the CCXT library to interact with various exchanges.
- Step 1: Create a Python file for the CCXT plugin at the following path: `data-service/src/exchange_source/plugins/ccxt_exchange.py`.
- Step 2: Define the `CCXTExchangeClient` class within this file, inheriting from `IExchangeAPIClient`.
- Implement the `get_exchange_name` method to return the name of the exchange instance (e.g., `"crypto.com"` for Crypto.com).
- Note: Use the Crypto.com exchange via CCXT for fetching historical OHLC data, as it provides up to two weeks of historical data.
- Note: Other CCXT-supported exchanges (e.g., Binance, Kraken, Coinbase) were tested but could not fulfill the two-week historical data requirement.
- Implement the `check_coin_availability` method using CCXT to fetch available markets from the exchange.
- Implement the `fetch_historical_data` method using the exchange's OHLC REST API via CCXT, handling pagination, rate limits, and translating data to the standardized internal format.
- Implement the `start_realtime_stream` method using the exchange's WebSocket API via CCXT (if supported), handling connection management and invoking the provided callback with real-time data translated to the standardized internal format.
- Implement any required authentication logic for interacting with the exchange API endpoints used.
- Implement a mechanism for this plugin to be discovered and registered with the `PluginRegistry` in the Data Service startup.

**Test Cases**
- Test File Path: `data-service/tests/unit/exchange_source/plugins/test_ccxt_exchange.py`
- Test that the plugin correctly implements all methods of `IExchangeAPIClient`.
- Test `get_exchange_name` returns the correct exchange name.
- Test `check_coin_availability` for a known available market.
- Test `check_coin_availability` for a non-existing market symbol.
- Test `fetch_historical_data` for a valid range: verify data is fetched via CCXT, translated, and returned correctly (mocking the CCXT client for unit tests).
- Test `fetch_historical_data` error handling for invalid inputs or ranges.
- Test `start_realtime_stream`: verify connection is established and the callback is invoked with real data entries (mocking the CCXT WebSocket client and the callback).
- Test handling of CCXT rate limits and errors within the plugin.
- Test data translation logic from CCXT exchange format to internal standard format.

### 2.5 Refine IRawDataStorage and Implement Multi-Exchange Storage:
- Update the IRawDataStorage interface and its implementations (LocalFileStorage, AzureBlobStorage stub) to handle storing data with an associated exchange_name (e.g., folder structure like [storage_root]/raw_data/[exchange_name]/[coin_symbol]/...). This is crucial for distinguishing data from different sources.

**Test Cases**
- Update tests from 1.4 and 1.5 to include exchange_name in method calls and verify data is stored/retrieved in exchange-specific locations.

## Iteration 3: Real-Time Data Collection & Storage Integration

**Goal**: Implement the real-time data collection flow, integrating the Data Source Connector and Storage Manager, and establish the system for managing download targets.

### 3.1 Design and Implement Target List Manager (using Delta Lake):
- **Purpose**: Implement a system to manage the list of targets (coin, exchange, interval, enabled status, etc.) that the service should download data for. This list will be managed programmatically by the system.
- **Technology**: Utilize a Delta Lake table managed via the `delta-rs` (`deltalake`) Python library. This provides ACID transactions, schema enforcement, and versioning for the target list.
- **Storage Modularity**: Design the implementation to support storing the Delta table on either the local filesystem or Azure Blob Storage, configurable at runtime.
- **Configuration**:
    - Define configuration settings (e.g., in `config.py` or environment variables) to specify:
        - `TARGET_STORAGE_TYPE`: `'local'` or `'azure'`.
        - `TARGET_TABLE_PATH`: Local path or Azure Blob URI (e.g., `az://<container>/targets_delta`).
        - `AZURE_STORAGE_OPTIONS`: Dictionary with Azure credentials/options if using Azure backend.
- **Implementation**:
    - Step 1: Create a new directory for this functionality: `data-service/src/target_management/`.
    - Step 2: Create a Python file for the manager implementation: `data-service/src/target_management/manager.py`.
    - Step 3: Define a `TargetManager` class within this file.
    - Step 4: Implement logic within `TargetManager` to:
        - Read configuration to determine storage backend (local/Azure) and path/options.
        - Initialize a `deltalake.DeltaTable` instance.
        - Handle initial table creation if it doesn't exist, defining the schema (e.g., `target_id`, `coin`, `exchange`, `exchange_id`, `interval`, `enabled`, `last_updated`, etc.).
        - Provide methods for CRUD operations: `add_target`, `update_target`, `delete_target`, `get_target`, `list_targets` (e.g., filtering by `enabled`).
        - Use `deltalake` functions (`write_deltalake`, `DeltaTable.update`, `DeltaTable.delete`, `DeltaTable.to_pandas`) for table interactions.
- **Dependencies**: Add `deltalake` to the project dependencies (`environment.yml`).

**Test Cases**
- Test File Path: `data-service/tests/unit/target_management/test_manager.py`
- Test initializing `TargetManager` with local storage configuration.
- Test initializing `TargetManager` with Azure storage configuration (mocking Azure connection).
- Test initial table creation if it doesn't exist (local and mocked Azure).
- Test `add_target`: verify data is written correctly (check resulting DataFrame/Parquet).
- Test `update_target`: verify predicate and updates work.
- Test `delete_target`: verify row is removed.
- Test `get_target` retrieves the correct row.
- Test `list_targets` returns correct rows, including filtering for enabled targets.
- Test handling of configuration errors (e.g., missing Azure options when type is Azure).
- Test handling of `deltalake` exceptions (e.g., schema mismatch, connection errors).

### 3.2 Design and Implement RealTimeProcessor:
- Implement RealTimeProcessor. This class will receive raw data entries (via a callback from the IExchangeAPIClient plugin), store them using IStorageManager, and prepare them for distribution.
- Step 1: Create a Python file for the processor at the following path: data-service/src/collection/processor.py.
- Step 2: Define the RealTimeProcessor class within this file.

**Test Cases**
- Test File Path: data-service/tests/unit/collection/test_processor.py
- Test that process_realtime_entry correctly calls IStorageManager.store_raw_data with the correct arguments.
- Test handling of storage errors within process_realtime_entry.
- Test that data is queued or prepared for distribution to subscribers.

### 3.3 Refine IDataCollectionManager and DataCollectionManagerImpl:
- Update the interface and implementation to include methods for adding coins (which involves selecting an exchange and telling the IDataSourceConnector to start the stream).
- Step 1: Create a Python file for the interface at the following path: data-service/src/collection/interfaces.py.
- Step 2: Define the IDataCollectionManager interface (using abc module) within this file.
- Implement logic to select the exchange when adding a coin (initially, a simple configuration-based selection).
- Wire up the RealTimeProcessor to receive data from the IExchangeAPIClient callback initiated by DataCollectionManagerImpl.
- Implement the logic to add a coin and its selected exchange to the CoinCollectionList.
- Step 3: Create a Python file for the manager implementation at the following path: data-service/src/collection/manager.py.
- Step 4: Define the DataCollectionManagerImpl class within this file, inheriting from IDataCollectionManager.
- Write unit tests for DataCollectionManagerImpl, focusing on adding coins and initiating streams (mocking IDataSourceConnector and IStorageManager).

**Test Cases**
- Test File Path: data-service/tests/unit/collection/test_manager.py
- Test add_coin for a new coin/exchange: verify check_availability is called, start_realtime_stream is called on the correct IExchangeAPIClient, and the coin is added to CoinCollectionList.
- Test add_coin for a coin that is not available: verify check_availability is called, start_realtime_stream is NOT called, and the coin is NOT added to CoinCollectionList.
- Test add_coin for a coin already being collected: verify it returns success without re-initiating the stream.
- Test the exchange selection logic (e.g., verify the correct exchange is selected based on config).
- Test that the callback provided to start_realtime_stream is the RealTimeProcessor's processing method.

## Iteration 4: Historical Data Handling & Storage Integration

**Goal**: Implement the historical data fetching flow, integrating the Data Source Connector and Storage Manager.

### 4.1 Design and Implement HistoricalFetcher:
- Implement HistoricalFetcher. This class will orchestrate fetching historical data, primarily from IStorageManager.
- Step 1: Create a Python file for the fetcher at the following path: data-service/src/historical/fetcher.py.
- Step 2: Define the HistoricalFetcher class within this file.
- (Optional, for later) Add logic to fetch from IExchangeAPIClient via IDataSourceConnector if data is not in storage.

**Test Cases**
- Test File Path: data-service/tests/unit/historical/test_fetcher.py
- Test fetch_data (or similar method) calls IStorageManager.get_raw_data_range with correct arguments.
- Test handling of data returned from storage.
- Test handling of empty results from storage.
- (For later) Test fetching from IDataSourceConnector if storage is incomplete.

### 4.2 Design and Implement CurrentDataFetcher:
- Implement CurrentDataFetcher. This class will retrieve the latest entry from IStorageManager.
- Step 1: Create a Python file for the current data fetcher at the following path: data-service/src/historical/current_fetcher.py.
- Step 2: Define the CurrentDataFetcher class within this file.

**Test Cases**
- Test File Path: data-service/tests/unit/historical/test_current_fetcher.py
- Test get_latest_entry calls IStorageManager.get_latest_entry with correct arguments.
- Test handling of data returned from storage.
- Test handling of None result from storage.

### 4.3 Refine IHistoricalDataManager and HistoricalDataManagerImpl:
- Update the interface and implementation to include methods for streaming historical data and getting the most current data.
- Step 1: Create a Python file for the interface at the following path: data-service/src/historical/interfaces.py.
- Step 2: Define the IHistoricalDataManager interface (using abc module) within this file.
- Wire up IHistoricalDataManagerImpl to use HistoricalFetcher and CurrentDataFetcher.
- Step 3: Create a Python file for the manager implementation at the following path: data-service/src/historical/manager.py.
- Step 4: Define the HistoricalDataManagerImpl class within this file, inheriting from IHistoricalDataManager.
- Write unit tests for IHistoricalDataManagerImpl, focusing on retrieving historical and current data (mocking IStorageManager).

**Test Cases**
- Test File Path: data-service/tests/unit/historical/test_manager.py
- Test stream_historical_data calls HistoricalFetcher to get data.
- Test stream_historical_data correctly formats and sends data chunks over the provided WebSocket (mocking the websocket).
- Test stream_historical_data sends a completion message after all data is streamed.
- Test stream_historical_data handles errors during streaming (e.g., broken websocket connection).
- Test get_most_current_data calls CurrentDataFetcher and returns the result.

## Iteration 5: API Endpoints (MCP & WebSocket)

**Goal**: Implement the external API for the Data Service using FastAPI, MCP, and WebSockets.

### 5.1 Set up FastAPI Application:
- Create the main FastAPI application instance.
- Install fastapi, uvicorn, fastapi_mcp, websockets.
- Step 1: Create the main application entry point file at the following path: data-service/src/main.py.
- Step 2: Initialize the FastAPI app instance within this file.

### 5.2 Design and Implement MCP Endpoints:
- Define MCP message structures (AddCoinRequest, AddCoinResponse, CheckAvailabilityRequest, CheckAvailabilityResponse, HistoricalDataRequest).
- Step 1: Create a Python file for MCP message models at the following path: data-service/src/models.py. Define Pydantic models for MCP messages within this file.
- Implement FastAPI endpoints using fastapi_mcp for Add Coin and Check Availability.
- Step 2: Create a Python file for the API endpoint handlers at the following path: data-service/src/api/endpoints.py.
- Step 3: Define FastAPI router(s) and endpoint functions within this file, using fastapi_mcp decorators/utilities.
- Wire these endpoints to call methods on IDataCollectionManager.
- Write integration tests for these MCP endpoints (mocking the underlying manager).

**Test Cases**
- Test File Path: data-service/tests/integration/api/test_mcp_endpoints.py
- Test Add Coin endpoint with valid request and token: verify manager method is called and success response is returned.
- Test Add Coin endpoint with invalid token: verify 401 Unauthorized is returned.
- Test Add Coin endpoint when manager returns failure: verify appropriate error response is returned.
- Test Check Availability endpoint with valid request and token: verify manager method is called and availability status is returned.
- Test Check Availability endpoint with invalid token: verify 401 Unauthorized is returned.

### 5.3 Design and Implement WebSocket Endpoint:
- Implement the main WebSocket endpoint (/ws/data) using FastAPI's WebSocket support.
- Step 1: Add the WebSocket endpoint implementation to the file created in 5.2: data-service/src/api/endpoints.py.
- Implement logic to handle incoming WebSocket messages (subscribe_realtime, request_historical, request_current).
- Wire these message handlers to call methods on IDataCollectionManager and IHistoricalDataManager.
- Implement logic to send data streams (realtime_data, historical_data_chunk, historical_data_complete) and responses (current_data_response) over the WebSocket.
- Write integration tests for the WebSocket endpoint (mocking managers and testing message flow).

**Test Cases**
- Test File Path: data-service/tests/integration/api/test_websocket_endpoint.py
- Test WebSocket connection handshake and authentication.
- Test subscribe_realtime message: verify IDataCollectionManager.add_coin and stream_realtime_data are called.
- Test request_historical message: verify IDataCollectionManager.add_coin and IHistoricalDataManager.stream_historical_data are called.
- Test request_current message: verify IHistoricalDataManager.get_most_current_data is called and the result is sent back over the WebSocket.
- Test sending real-time data messages over the WebSocket to a subscribed client.
- Test sending historical data chunks and completion message over the WebSocket.
- Test handling of invalid WebSocket messages.
- Test handling of WebSocket disconnection.

### 5.4 Wire up Dependencies:
- In the Data Service's main application startup (data-service/src/main.py), instantiate all concrete implementations (DataCollectionManagerImpl, HistoricalDataManagerImpl, StorageManagerImpl, DataSourceConnectorImpl, AuthenticationModuleImpl) and inject them into the API endpoint handlers and each other where needed. Inject the chosen IRawDataStorage implementation into StorageManagerImpl.

## Iteration 6: Authentication & Security

**Goal**: Implement OAuth authentication for securing the Data Service.

### 6.1 Design and Implement IAuthenticationModule and AuthenticationModuleImpl:
- Define the IAuthenticationModule interface.
- Step 1: Create a Python file for the interface at the following path: data-service/src/auth/interfaces.py.
- Step 2: Define the IAuthenticationModule interface (using abc module) within this file.
- Implement AuthenticationModuleImpl containing the logic for token validation. This might involve integration with an external auth provider or a simple internal check for initial development.
- Step 3: Create a Python file for the implementation at the following path: data-service/src/auth/module.py.
- Step 4: Define the AuthenticationModuleImpl and TokenValidator classes within this file, with AuthenticationModuleImpl depending on TokenValidator.

**Test Cases**
- Test File Path: data-service/tests/unit/auth/test_module.py
- Test validate_token with a valid token: verify it returns the expected user identifier.
- Test validate_token with an invalid token: verify it returns None.
- Test validate_token with an expired token (if applicable): verify it returns None.

### 6.2 Integrate OAuth2 into FastAPI Endpoints:
- Use FastAPI's OAuth2PasswordBearer and Depends to secure the MCP and WebSocket endpoints.
- Implement the get_current_user dependency function that uses IAuthenticationModule.
- Step 1: Add the get_current_user dependency function definition to the file created in 6.1: data-service/src/auth/module.py. This function will depend on IAuthenticationModule.
- Step 2: Update the API endpoint handlers in data-service/src/api/endpoints.py to use the Depends(get_current_user) dependency.
- Write integration tests to ensure endpoints require authentication.

**Test Cases**
- Test File Path: data-service/tests/integration/api/test_secured_endpoints.py
- Test accessing a secured endpoint with a valid token: verify access is granted.
- Test accessing a secured endpoint without a token: verify 401 Unauthorized is returned.
- Test accessing a secured endpoint with an invalid token: verify 401 Unauthorized is returned.
- Test accessing an unsecured endpoint (if any) without a token: verify access is granted.

## Iteration 7: Azure Storage Implementation & Multi-Exchange Plugins

**Goal**: Implement the Azure Storage backend and add support for real exchange plugins.

### 7.1 Implement AzureBlobStorage:
- Implement the concrete class AzureBlobStorage, completing its implementation of IRawDataStorage using the Azure Blob Storage SDK.
- Step 1: Update the file created in 1.5: data-service/src/storage/implementations/azure_blob_storage.py.
- This class will also use the StoragePathUtility to construct blob paths/names.
- Implement logic for connecting to Azure, creating containers/folders, and reading/writing blobs according to the defined file structure, using the Azure Blob Storage SDK.
- Write unit tests for AzureBlobStorage.

**Test Cases**
- Test File Path: data-service/tests/unit/storage/implementations/test_azure_blob_storage.py
- Test save_entry to Azure Blob Storage: verify blob is created in the correct container/path.
- Test get_range from Azure Blob Storage: verify correct blobs are retrieved and data is parsed.
- Test get_latest_entry from Azure Blob Storage: verify the most recent blob is retrieved.
- Test list_coins from Azure Blob Storage: verify correct list of coin folders is returned.
- Test check_coin_exists in Azure Blob Storage: verify existence check works correctly.
- Test handling of Azure API errors (e.g., connection issues, authentication failures).

### 7.2 Implement Real IExchangeAPIClient Plugins:
- Choose one or two real exchange APIs (e.g., Binance, Coinbase).
- Implement concrete IExchangeAPIClient classes for these exchanges, handling their specific APIs, data formats, authentication, and rate limits.
- Step 1: Create a new directory for plugins if it doesn't exist: data-service/src/exchange_source/plugins/.
- Step 2: Create a Python file for each real exchange plugin (e.g., data-service/src/exchange_source/plugins/binance_exchange.py, data-service/src/exchange_source/plugins/coinbase_exchange.py).
- Step 3: Define the concrete IExchangeAPIClient class for each exchange within its respective file, inheriting from IExchangeAPIClient.
- Ensure they translate data to the standardized internal format.
- Implement the plugin discovery mechanism to pick up these new plugins.

**Test Cases**
- Test File Path: data-service/tests/unit/exchange_source/plugins/test_[exchange_name]_exchange.py (e.g., test_binance_exchange.py)
- Test that each real plugin correctly implements IExchangeAPIClient.
- Test get_exchange_name for each plugin returns the correct exchange name.
- Test check_coin_availability for a real coin on the exchange.
- Test fetch_historical_data for a valid range: verify data is fetched, translated, and returned correctly.
- Test fetch_historical_data with invalid inputs or ranges: verify error handling.
- Test start_realtime_stream: verify connection is established and the callback is invoked with real data entries (requires mocking the callback).
- Test handling of exchange API rate limits and errors within the plugin.
- Test data translation logic from exchange format to internal standard format.

### 7.3 Refine Exchange Selection Logic:
- Update DataCollectionManagerImpl to handle scenarios where a coin might be available on multiple exchanges, potentially using a more sophisticated selection strategy later.

**Test Cases**
- Test File Path: data-service/tests/unit/collection/test_manager.py (Add tests to existing manager tests)
- Test exchange selection with a simple config mapping.
- Test exchange selection when the preferred exchange is not available (falls back or reports failure).

### 7.4 Refine Historical Data Fetching (from Source):
- Implement the logic in IHistoricalDataManagerImpl and HistoricalFetcher to fetch historical data from the IDataSourceConnector (using the real exchange plugins) if it's not found in storage for the requested range.

**Test Cases**
- Test File Path: data-service/tests/unit/historical/test_fetcher.py (Add tests to existing fetcher tests)
- Test stream_historical_data fetches data from storage first, then from the exchange if needed for the range.
- Test handling of overlapping data between storage and exchange fetch.
- Test error handling if fetching from the exchange fails.

### 7.5 Comprehensive Testing:
- Write end-to-end integration tests for the Data Service, simulating client requests and verifying data flow through the system with different storage backends (LocalFileStorage and AzureBlobStorage) and real exchange plugins.

**Test Cases**
- Test File Path: data-service/tests/integration/test_data_service_e2e.py
- Simulate adding a new coin and verify real-time data flows to storage and subscribers.
- Simulate requesting historical data for a range fully in storage: verify data is streamed correctly.
- Simulate requesting historical data for a range partially in storage and partially on the exchange: verify data is fetched from both sources and streamed correctly.
- Simulate requesting historical data for a range only on the exchange: verify data is fetched and streamed correctly.
- Simulate requesting the most current data.
- Simulate multiple clients subscribing to real-time data for the same coin.
- Simulate errors in the data feed or storage and verify graceful handling/logging.
- Test with different exchange plugins active.

## Iteration 8: CI/CD Pipeline for Data Service

**Goal**: Automate testing and deployment of the Data Service to Azure Container Instances (ACI).

### 8.1 Set up CI Pipeline:
- Configure a CI server (e.g., Jenkins, GitHub Actions, Azure DevOps Pipelines).
- Automate building the Data Service code, running unit tests and integration tests on every code push.
- Automate building the Docker container image for the Data Service.

### 8.2 Set up CD Pipeline:
- Automate deploying the Data Service container image to Azure Container Instances (ACI) upon successful CI build.
- Implement basic health checks for the deployed ACI instance.

This phased iteration plan provides a structured approach to building the Data Service, starting with foundational components and gradually adding complexity and features, incorporating the specific requirements for file-based storage, multiple storage backends, the Microkernel pattern for exchange connectors, deployment to Azure Container Instances (ACI), and detailed test cases with suggested file paths for each implementation step using pytest. Remember to prioritize writing tests at each step to ensure the reliability of your service.